import os
import sys
import json
import yaml
import time
import random
import re
import logging
import traceback
from datetime import datetime
from pathlib import Path
from typing import Set, List, Tuple, Dict, Optional

# --- æ—¥å¿—é…ç½® ---
def setup_logging(log_dir: str, config_name: str = "main"):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿï¼Œè¿”å›æ—¥å¿—å™¨"""
    Path(log_dir).mkdir(exist_ok=True)
    
    # åˆ›å»ºå›½å®¶æ—¥å¿—ç›®å½•
    countries_dir = os.path.join(log_dir, "countries")
    Path(countries_dir).mkdir(exist_ok=True)
    
    # ä¸»æ—¥å¿—æ–‡ä»¶
    main_log_file = os.path.join(log_dir, f"sync_{datetime.now().strftime('%Y%m%d')}.log")
    
    # ç¼ºå¤±è§†é¢‘ä¸“ç”¨æ—¥å¿—æ–‡ä»¶
    missing_log_file = os.path.join(log_dir, f"missing_{datetime.now().strftime('%Y%m%d')}.log")
    
    # é…ç½®æ ¹æ—¥å¿—å™¨
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.FileHandler(main_log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    # åˆ›å»ºä¸“é—¨è®°å½•ç¼ºå¤±è§†é¢‘çš„æ—¥å¿—å™¨
    missing_logger = logging.getLogger('missing_logger')
    missing_logger.setLevel(logging.INFO)
    
    # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
    if not missing_logger.handlers:
        missing_handler = logging.FileHandler(missing_log_file, encoding='utf-8')
        missing_handler.setFormatter(logging.Formatter('%(asctime)s | %(message)s'))
        missing_logger.addHandler(missing_handler)
    
    return logging.getLogger(__name__), missing_logger, countries_dir

# --- é…ç½®åŠ è½½ ---
def load_config(config_path: str = "config.yaml") -> dict:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºé»˜è®¤é…ç½®"""
    try:
        if not os.path.exists(config_path):
            # è‡ªåŠ¨ç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶
            default_config = {
                "local_roots": ["F:\\ä½œå“"],
                "output_dir": "output",
                "log_dir": "log",
                "video_extensions": ["mp4", "avi", "mov", "wmv", "flv", "mkv", "rmvb"],
                "filename_clean_patterns": [
                    r"(?i)\[.*?\]",
                    r"(?i)\(.*?\)",
                    r"(?i)\{.*?\}"
                ],
                "use_selenium": True,
                "max_pages": -1,
                "delay_between_pages": {
                    "min": 2.0,
                    "max": 3.5
                },
                "retry_on_fail": 2
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(default_config, f, allow_unicode=True, default_flow_style=False)
            print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²è‡ªåŠ¨åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {config_path}")
            return default_config
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config_text = f.read()
            config_text = config_text.replace('\\', '\\\\')
            return yaml.safe_load(config_text)
    except Exception as e:
        print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)

def load_models(model_path: str = "models.json") -> dict:
    """åŠ è½½æ¨¡ç‰¹é…ç½®JSONæ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºç©ºæ–‡ä»¶"""
    try:
        if not os.path.exists(model_path):
            # è‡ªåŠ¨ç”Ÿæˆç©ºçš„æ¨¡ç‰¹é…ç½®æ–‡ä»¶
            with open(model_path, 'w', encoding='utf-8') as f:
                json.dump({}, f, ensure_ascii=False, indent=2)
            print(f"æ¨¡ç‰¹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²è‡ªåŠ¨åˆ›å»ºç©ºæ–‡ä»¶: {model_path}")
            return {}
        
        with open(model_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # æ£€æŸ¥æ˜¯å¦æ˜¯schemaæ ¼å¼ï¼Œå¦‚æœæ˜¯ï¼Œå°è¯•è·å–examplesä¸­çš„æ¨¡ç‰¹æ•°æ®
            if 'examples' in data and len(data['examples']) > 0:
                example = data['examples'][0]
                if 'models' in example:
                    return example['models']
            # æ£€æŸ¥æ˜¯å¦æ˜¯åµŒå¥—æ ¼å¼ï¼Œå¦‚ {"models": {"æ¨¡ç‰¹å": "URL"}}
            elif 'models' in data:
                return data['models']
            # å¦‚æœä¸æ˜¯schemaæ ¼å¼ï¼Œç›´æ¥è¿”å›
            return data
    except Exception as e:
        print(f"æ¨¡ç‰¹é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)

# --- ç¼“å­˜ç®¡ç† --- 
def get_cache_dir(config: dict) -> str:
    """è·å–ç¼“å­˜ç›®å½•è·¯å¾„"""
    # ç¡®ä¿outputç›®å½•å­˜åœ¨
    output_dir = config['output_dir']
    Path(output_dir).mkdir(exist_ok=True)
    
    # ç„¶ååˆ›å»ºç¼“å­˜ç›®å½•
    cache_dir = os.path.join(output_dir, 'cache')
    Path(cache_dir).mkdir(exist_ok=True)
    return cache_dir

def get_model_cache_path(cache_dir: str, model_name: str) -> str:
    """è·å–æ¨¡ç‰¹ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
    safe_model_name = re.sub(r'[^\w\-]', '_', model_name)
    return os.path.join(cache_dir, f"{safe_model_name}.json")

def load_cache(cache_path: str) -> Set[str]:
    """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
    if not os.path.exists(cache_path):
        return set()
    
    try:
        with open(cache_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return set(data.get('video_titles', []))
    except Exception as e:
        logging.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
        return set()

def save_cache(cache_path: str, video_titles: Set[str], model_name: str, url: str):
    """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
    try:
        data = {
            'model_name': model_name,
            'url': url,
            'video_titles': list(video_titles),
            'last_updated': datetime.now().isoformat()
        }
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

# --- æœ¬åœ°æ–‡ä»¶å¤„ç†ï¼ˆæ”¯æŒå¤šå±‚æ–‡ä»¶å¤¹ï¼‰---
def clean_filename(name: str, patterns: List[str]) -> str:
    """æ¸…ç†æ–‡ä»¶åä¸­çš„å¹²æ‰°é¡¹"""
    original_name = name
    
    for pat in patterns:
        try:
            name = re.sub(pat, '', name, flags=re.IGNORECASE)
        except re.error as e:
            logging.debug(f"æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯ '{pat}': {e}")
            # å°è¯•ä¸å¸¦æ ‡å¿—çš„æ­£åˆ™è¡¨è¾¾å¼
            try:
                name = re.sub(pat, '', name)
            except:
                pass
    
    cleaned = name.strip()
    
    # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œåˆ†éš”ç¬¦
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = re.sub(r'[_\-\.]+', ' ', cleaned)
    cleaned = cleaned.strip(' _-.')
    
    # ç§»é™¤å¸¸è§çš„è§†é¢‘æ ‡è¯†
    # å…ˆç§»é™¤æ–‡ä»¶åå¼€å¤´çš„[æ¨¡ç‰¹å]å‰ç¼€
    cleaned = re.sub(r'^\[.*?\]\s*', '', cleaned)
    # å†ç§»é™¤æœ«å°¾çš„å“ˆå¸Œå€¼æˆ–å…¶ä»–æ ‡è¯†
    cleaned = re.sub(r'\s*\([^\)]*?\)\s*$', '', cleaned)
    
    # å…¨é¢çš„å­—ç¬¦ç»Ÿä¸€å¤„ç†
    # 1. å…¨è§’è½¬åŠè§’
    full_to_half = {}
    for i in range(0xFF01, 0xFF5F + 1):
        full_to_half[chr(i)] = chr(i - 0xFEE0)
    # ç‰¹æ®Šå¤„ç†ç©ºæ ¼
    full_to_half['ã€€'] = ' '
    # åº”ç”¨å…¨è§’è½¬åŠè§’
    cleaned = ''.join([full_to_half.get(c, c) for c in cleaned])
    
    # 2. ç‰¹æ®Šå­—ç¬¦ç»Ÿä¸€
    # ç»Ÿä¸€å¤„ç†ç ´æŠ˜å·ï¼šå°†æ‰€æœ‰ç±»å‹çš„ç ´æŠ˜å·è½¬æ¢ä¸ºæ ‡å‡†çš„hyphen
    cleaned = re.sub(r'[\u2013\u2014\u2015]', '-', cleaned)
    # ç»Ÿä¸€å¤„ç†å¼•å·ï¼šå°†æ‰€æœ‰ç±»å‹çš„å¼•å·è½¬æ¢ä¸ºæ ‡å‡†çš„å•å¼•å·
    cleaned = re.sub(r'[\u2018\u2019\u201c\u201d]', "'", cleaned)
    # ç»Ÿä¸€å¤„ç†çœç•¥å·ï¼šå°†æ‰€æœ‰ç±»å‹çš„çœç•¥å·è½¬æ¢ä¸ºæ ‡å‡†çš„ä¸‰ä¸ªç‚¹
    cleaned = re.sub(r'[\u2026]', '...', cleaned)
    # ç»Ÿä¸€å¤„ç†æ–œæ ï¼šå°†å…¨è§’æ–œæ è½¬æ¢ä¸ºåŠè§’æ–œæ 
    cleaned = re.sub(r'[\uFF0F]', '/', cleaned)
    
    # 3. ç©ºæ ¼å’Œåˆ†éš”ç¬¦æ ‡å‡†åŒ–
    # ç»Ÿä¸€å¤„ç†ç©ºæ ¼ï¼šå°†å¤šä¸ªè¿ç»­ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    cleaned = re.sub(r'\s+', ' ', cleaned)
    # ç§»é™¤åˆ†è¾¨ç‡å’Œè§†é¢‘è´¨é‡æ ‡è¯†
    cleaned = re.sub(r'\d{3,4}[xp]\d{3,4}', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'\d{3,4}p', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'\b(hd|fhd|uhd|4k|fullhd)\b', '', cleaned, flags=re.IGNORECASE)
    # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œåˆ†éš”ç¬¦
    cleaned = re.sub(r'[\s_\-\.]+', ' ', cleaned)
    cleaned = cleaned.strip(' _-.')
    
    if original_name != cleaned:
        logging.debug(f"æ¸…ç†æ–‡ä»¶å: '{original_name}' -> '{cleaned}'")
    
    return cleaned.strip()

def extract_local_videos(folder: str, video_exts: Set[str], 
                        clean_patterns: List[str]) -> Set[str]:
    """
    æå–æœ¬åœ°è§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒå¤šå±‚æ–‡ä»¶å¤¹ç»“æ„
    é€’å½’æ‰«æå­æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶
    """
    videos = set()
    
    if not os.path.exists(folder):
        return videos
    
    # é€’å½’æ‰«ææ‰€æœ‰å­ç›®å½•
    for root_dir, _, files in os.walk(folder):
        for file in files:
            name, ext = os.path.splitext(file)
            
            if ext.lower() in video_exts:
                cleaned = clean_filename(name, clean_patterns)
                if cleaned:
                    videos.add(cleaned)
                else:
                    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹åç§°
                    cleaned_name = name.strip()
                    cleaned_name = re.sub(r'[\[\]\(\)].*?[\[\]\(\)]', '', cleaned_name)
                    videos.add(cleaned_name)
    
    return videos

def record_missing_videos(model_name: str, url: str, missing_titles: List[Tuple[str, str]], 
                         missing_logger, logger, local_count=0, online_count=0):
    """è®°å½•ç¼ºå¤±è§†é¢‘åˆ°ä¸“ç”¨æ—¥å¿—æ–‡ä»¶"""
    if not missing_titles and not online_count:
        return
    
    missing_logger.info("=" * 60)
    missing_logger.info(f"æ¨¡ç‰¹: {model_name}")
    missing_logger.info(f"é“¾æ¥: {url}")
    if online_count > 0:
        missing_logger.info(f"ç¼ºå¤±è§†é¢‘æ•°é‡: {len(missing_titles)}")
        missing_logger.info(f"æ€»è§†é¢‘æ•°é‡: {online_count} | æœ¬åœ°è§†é¢‘: {local_count} | ç¼ºå¤±è§†é¢‘: {len(missing_titles)}")
    else:
        missing_logger.info(f"ç¼ºå¤±è§†é¢‘æ•°é‡: {len(missing_titles)}")
    missing_logger.info("-" * 40)
    
    for i, (title, video_url) in enumerate(missing_titles, 1):
        if video_url:
            missing_logger.info(f"{i:3d}. {title}")
            missing_logger.info(f"    é“¾æ¥: {video_url}")
        else:
            missing_logger.info(f"{i:3d}. {title}")
    
    missing_logger.info("=" * 60 + "\n")
    logger.warning(f"  ğŸ”´ ç¼ºå¤± {len(missing_titles)} ä¸ªè§†é¢‘ï¼Œå·²è®°å½•åˆ°ç¼ºå¤±æ—¥å¿—")
