import os
import sys
import json
import time
import random
import logging
import traceback
import threading
from datetime import datetime
from pathlib import Path
from typing import Set, List, Tuple, Dict, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥æ¨¡å—åŒ–çš„åŠŸèƒ½
from core.modules.common.common import (
    setup_logging,
    load_config,
    load_models,
    get_cache_dir,
    get_model_cache_path,
    load_cache,
    save_cache,
    extract_local_videos,
    extract_local_folders,
    record_missing_videos,
    test_proxy_connection,
    get_smart_cache
)

# å¯¼å…¥é…ç½®éªŒè¯æ¨¡å—
from core.modules.common.config_validator import validate_config_file, print_validation_report

# å¯¼å…¥ChromeDriverç®¡ç†æ¨¡å—
from core.modules.common.chrome_driver_manager import check_and_setup_chromedriver

# å¯¼å…¥å¢å¼ºç‰ˆä»£ç†æ£€æŸ¥æ¨¡å—
from core.modules.common.enhanced_proxy_checker import EnhancedProxyTester, print_comprehensive_report

from core.modules.common.smart_cache import SmartCache

from core.modules.porn.porn import (
    fetch_with_requests_porn,
    scan_porn_models
)

from core.modules.javdb.javdb import (
    fetch_with_requests_javdb,
    scan_javdb_models
)


@dataclass
class ModelResult:
    """æ¨¡ç‰¹å¤„ç†ç»“æœæ•°æ®ç±»"""
    model_name: str
    success: bool
    local_count: int = 0
    online_count: int = 0
    new_videos_count: int = 0
    missing_count: int = 0
    missing_titles: List[str] = field(default_factory=list)
    missing_with_urls: List[Tuple[str, str]] = field(default_factory=list)
    error_message: str = ""
    url: str = ""
    local_folder: str = ""
    country: str = ""
    local_folder_full: str = ""  # æœ¬åœ°ç›®å½•å®Œæ•´è·¯å¾„


class ModelProcessor:
    """æ¨¡ç‰¹å¤„ç†å™¨ - æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘å¤„ç†"""
    
    def __init__(self, config: dict, module_type: int, logger: logging.Logger, 
                 missing_logger: logging.Logger, countries_dir: str, 
                 smart_cache: SmartCache, running_flag=None):
        """
        åˆå§‹åŒ–æ¨¡ç‰¹å¤„ç†å™¨
        
        Args:
            config: é…ç½®å­—å…¸
            module_type: æ¨¡å—ç±»å‹ (1=PORN, 2=JAVDB, 3=AUTO)
            logger: ä¸»æ—¥å¿—è®°å½•å™¨
            missing_logger: ç¼ºå¤±è§†é¢‘æ—¥å¿—è®°å½•å™¨
            countries_dir: å›½å®¶åˆ†ç±»ç›®å½•
            smart_cache: æ™ºèƒ½ç¼“å­˜å®ä¾‹
            running_flag: è¿è¡Œæ ‡å¿—
        """
        self.config = config
        self.module_type = module_type
        self.logger = logger
        self.missing_logger = missing_logger
        self.countries_dir = countries_dir
        self.smart_cache = smart_cache
        self.running_flag = running_flag
        
        # çº¿ç¨‹æœ¬åœ°å­˜å‚¨ï¼Œæ¯ä¸ªçº¿ç¨‹æœ‰è‡ªå·±çš„ Selenium å®ä¾‹
        self._thread_local = threading.local()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.processed_count = 0
        self.error_count = 0
        self._stats_lock = threading.Lock()
    
    def _should_stop(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢å¤„ç†"""
        if self.running_flag is None:
            return False
        
        if callable(self.running_flag):
            return not self.running_flag()
        return not self.running_flag
    
    def _update_stats(self, success: bool):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self._stats_lock:
            if success:
                self.processed_count += 1
            else:
                self.error_count += 1
    
    def process_single_model(self, model_info: Tuple) -> ModelResult:
        """
        å¤„ç†å•ä¸ªæ¨¡ç‰¹ï¼ˆä¾›å¤šçº¿ç¨‹è°ƒç”¨ï¼‰
        
        Args:
            model_info: (model_name, folder, original_dir, country) å…ƒç»„
            
        Returns:
            ModelResult å¤„ç†ç»“æœ
        """
        model_name, folder, original_dir, country = model_info
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if self._should_stop():
            return ModelResult(
                model_name=model_name,
                success=False,
                error_message="ç”¨æˆ·è¯·æ±‚åœæ­¢",
                local_folder_full=original_dir
            )
        
        # è·å–å½“å‰çº¿ç¨‹ID
        thread_id = threading.current_thread().ident
        self.logger.info(f"[çº¿ç¨‹-{thread_id}] å¼€å§‹å¤„ç†æ¨¡ç‰¹: {model_name} (å›½å®¶: {country})")
        
        try:
            # åˆ›å»ºå›½å®¶ç›®å½•
            country_dir = os.path.join(self.countries_dir, country)
            Path(country_dir).mkdir(exist_ok=True)
            
            # æå–æœ¬åœ°æ ‡é¢˜
            if self.module_type == 1 or (self.module_type == 3 and '[Channel]' in original_dir):
                local_set = extract_local_videos(
                    folder,
                    set(self.config['video_extensions']),
                    self.config['filename_clean_patterns']
                )
                self.logger.info(f"[çº¿ç¨‹-{thread_id}] {model_name}: æœ¬åœ°è§†é¢‘æ–‡ä»¶ {len(local_set)} ä¸ª")
            else:
                local_set = extract_local_folders(folder)
                self.logger.info(f"[çº¿ç¨‹-{thread_id}] {model_name}: æœ¬åœ°æ–‡ä»¶å¤¹ {len(local_set)} ä¸ª")
            
            # è·å–æ¨¡ç‰¹URL
            models = load_models()
            url = models.get(model_name)
            if not url:
                self.logger.error(f"[çº¿ç¨‹-{thread_id}] {model_name}: é…ç½®ä¸­æœªæ‰¾åˆ°URL")
                self._update_stats(False)
                return ModelResult(
                    model_name=model_name,
                    success=False,
                    error_message="æœªæ‰¾åˆ°URL",
                    local_count=len(local_set),
                    country=country,
                    local_folder=original_dir,
                    local_folder_full=folder
                )
            
            # æŠ“å–åœ¨çº¿è§†é¢‘æ ‡é¢˜ï¼ˆä½¿ç”¨æ™ºèƒ½ç¼“å­˜ï¼‰
            max_pages = self.config.get('max_pages', -1)
            max_retries = self.config.get('retry_on_fail', 2)
            
            online_set = set()
            title_to_url = {}
            
            for attempt in range(max_retries + 1):
                if self._should_stop():
                    return ModelResult(
                        model_name=model_name,
                        success=False,
                        error_message="ç”¨æˆ·è¯·æ±‚åœæ­¢",
                        local_folder_full=original_dir
                    )
                
                try:
                    # æ ¹æ®æ¨¡å—ç±»å‹é€‰æ‹©æŠ“å–å‡½æ•°ï¼Œä¼ å…¥æ™ºèƒ½ç¼“å­˜
                    if self.module_type == 1 or (self.module_type == 3 and '[Channel]' in original_dir):
                        online_set, title_to_url = fetch_with_requests_porn(
                            url, self.logger, max_pages, self.config,
                            self.smart_cache, model_name
                        )
                    else:
                        online_set, title_to_url = fetch_with_requests_javdb(
                            url, self.logger, max_pages, self.config,
                            self.smart_cache, model_name
                        )
                    
                    if online_set:
                        break
                    
                    if attempt < max_retries:
                        retry_delay = (attempt + 1) * 5
                        self.logger.warning(f"[çº¿ç¨‹-{thread_id}] {model_name}: ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                        time.sleep(retry_delay)
                        
                except Exception as e:
                    self.logger.error(f"[çº¿ç¨‹-{thread_id}] {model_name}: æŠ“å–å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}")
                    if attempt < max_retries:
                        time.sleep(5)
            
            if not online_set:
                self.logger.error(f"[çº¿ç¨‹-{thread_id}] {model_name}: è·å–åœ¨çº¿æ ‡é¢˜å¤±è´¥")
                self._update_stats(False)
                return ModelResult(
                    model_name=model_name,
                    success=False,
                    error_message="è·å–åœ¨çº¿æ ‡é¢˜å¤±è´¥",
                    local_count=len(local_set),
                    country=country,
                    local_folder=original_dir,
                    local_folder_full=folder,
                    url=url
                )
            
            # è·å–å·²ç¼“å­˜çš„æ ‡é¢˜
            cached_titles = self.smart_cache.get_cached_titles(model_name)
            new_videos = online_set - cached_titles
            
            # è·å–ä¹‹å‰å·²ä¸‹è½½çš„è§†é¢‘ï¼ˆä»ç¼“å­˜ä¸­æ ‡è®°ä¸ºdownloadedçš„è§†é¢‘ï¼‰
            # è¿™æ ·åç»­è¿è¡Œæ—¶ï¼Œå·²ä¸‹è½½çš„è§†é¢‘ä¸ä¼šå†å‡ºç°åœ¨ç¼ºå¤±åˆ—è¡¨ä¸­
            downloaded_videos = set()
            if self.smart_cache and self.smart_cache.enabled:
                # ç›´æ¥è¯»å–ç¼“å­˜æ•°æ®ä¸­çš„missing_videosï¼Œç­›é€‰status='downloaded'çš„
                cache_data = self.smart_cache.load(model_name)
                missing_data = cache_data.get('missing_videos', {})
                for title, info in missing_data.items():
                    if info.get('status') == 'downloaded':
                        downloaded_videos.add(title)
            
            # åˆå¹¶æœ¬åœ°è§†é¢‘å’Œå·²ä¸‹è½½è§†é¢‘
            local_set_with_downloaded = local_set | downloaded_videos
            
            # å¯¹æ¯”æ‰¾å‡ºç¼ºå¤±è§†é¢‘ï¼ˆç”¨æ‰€æœ‰åœ¨çº¿è§†é¢‘å¯¹æ¯”ï¼Œä¸åªæ˜¯æ–°å¢çš„ï¼‰
            missing = online_set - local_set_with_downloaded
            
            # è®°å½•åŸå§‹æœ¬åœ°æ•°é‡å’Œå®é™…ç”¨äºå¯¹æ¯”çš„æ•°é‡
            original_local_count = len(local_set)
            effective_local_count = len(local_set_with_downloaded)
            
            self.logger.info(f"[çº¿ç¨‹-{thread_id}] {model_name}: åœ¨çº¿ {len(online_set)} | æ–°è§†é¢‘ {len(new_videos)} | æœ¬åœ° {original_local_count} | å·²ä¸‹è½½{len(downloaded_videos)} | æœ‰æ•ˆæœ¬åœ° {effective_local_count} | ç¼ºå¤± {len(missing)}")
            
            self._update_stats(True)
            
            # æ„å»ºç»“æœ
            result = ModelResult(
                model_name=model_name,
                success=True,
                local_count=effective_local_count,  # ä½¿ç”¨æœ‰æ•ˆçš„æœ¬åœ°è§†é¢‘æ•°é‡ï¼ˆåŒ…å«å·²ä¸‹è½½çš„ï¼‰
                online_count=len(online_set),
                new_videos_count=len(new_videos),
                missing_count=len(missing),
                missing_titles=sorted(list(missing)),
                missing_with_urls=[(title, title_to_url.get(title, "")) for title in missing],
                url=url,
                local_folder=original_dir,
                local_folder_full=folder,
                country=country
            )
            
            # å¦‚æœæœ‰ç¼ºå¤±è§†é¢‘ï¼Œè®°å½•åˆ°æ—¥å¿—
            if missing:
                sorted_missing = sorted(list(missing))
                missing_with_urls = [(title, title_to_url.get(title, "")) for title in sorted_missing]
                
                # çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—è®°å½•
                with threading.Lock():
                    # è·å–æ—¥å¿—æ¨¡æ¿ç±»å‹
                    template_type = self.config.get('porn', {}).get('missing_log_template', 'simple')
                    record_missing_videos(
                        model_name, url, missing_with_urls,
                        self.missing_logger, self.logger,
                        local_count=len(local_set), online_count=len(online_set),
                        template_type=template_type
                    )
                
                # ä¿å­˜å›½å®¶-æ¨¡ç‰¹çš„è¯¦ç»†æŠ¥å‘Š
                country_model_dir = os.path.join(self.countries_dir, country, model_name)
                Path(country_model_dir).mkdir(parents=True, exist_ok=True)
                
                # åˆ›å»ºç¼ºå¤±è§†é¢‘ç›®å½•
                missing_dir = os.path.join(country_model_dir, "ç¼ºå¤±")
                Path(missing_dir).mkdir(exist_ok=True)
                
                country_model_report = os.path.join(
                    country_model_dir,
                    f"{model_name}_report_{datetime.now().strftime('%Y%m%d')}.txt"
                )
                
                with threading.Lock():
                    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
                    with open(country_model_report, 'w', encoding='utf-8') as f:
                        f.write("=" * 60 + "\n")
                        f.write(f"æ¨¡ç‰¹: {model_name}\n")
                        f.write(f"å›½å®¶: {country}\n")
                        f.write(f"é“¾æ¥: {url}\n")
                        f.write(f"æœ¬åœ°ç›®å½•: {original_dir}\n")
                        f.write(f"å®Œæ•´è·¯å¾„: {folder}\n")
                        f.write(f"ç»Ÿè®¡: åœ¨çº¿ {len(online_set)} ä¸ª | æ–°è§†é¢‘ {len(new_videos)} ä¸ª | æœ¬åœ° {len(local_set)} ä¸ª | ç¼ºå¤± {len(missing)} ä¸ª\n")
                        f.write(f"å¤„ç†æ¨¡å—: {'PORN' if self.module_type == 1 or ('[Channel]' in original_dir and self.module_type == 3) else 'JAVDB'}\n")
                        f.write("=" * 60 + "\n\n")
                        
                        if missing:
                            f.write("ç¼ºå¤±è§†é¢‘åˆ—è¡¨:\n")
                            f.write("-" * 40 + "\n")
                            for i, (title, video_url) in enumerate(missing_with_urls, 1):
                                f.write(f"{i:3d}. {title}\n")
                                if video_url:
                                    f.write(f"    é“¾æ¥: {video_url}\n")
                            f.write("\n" + "=" * 60 + "\n")
                        else:
                            f.write("âœ… æœ¬åœ°è§†é¢‘å®Œæ•´ï¼Œæ— ç¼ºå¤±\n")
                            f.write("\n" + "=" * 60 + "\n")
                    
                    # å¦‚æœæœ‰ç¼ºå¤±è§†é¢‘ï¼Œç”Ÿæˆç¼ºå¤±è§†é¢‘é“¾æ¥æ–‡ä»¶
                    if missing and missing_with_urls:
                        missing_links_file = os.path.join(missing_dir, f"{model_name}_ç¼ºå¤±é“¾æ¥_{datetime.now().strftime('%Y%m%d')}.txt")
                        with open(missing_links_file, 'w', encoding='utf-8') as f:
                            f.write(f"# {model_name} ç¼ºå¤±è§†é¢‘é“¾æ¥\n")
                            f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                            f.write(f"# æ€»æ•°é‡: {len(missing_with_urls)}\n")
                            f.write("# " + "=" * 58 + "\n\n")
                            
                            for i, (title, video_url) in enumerate(missing_with_urls, 1):
                                f.write(f"{title}\n")
                                if video_url:
                                    f.write(f"{video_url}\n")
                                f.write("\n")
                        
                        self.logger.info(f"[çº¿ç¨‹-{thread_id}] {model_name}: ğŸ“ ç¼ºå¤±é“¾æ¥å·²ä¿å­˜")
                        
                        # æ›´æ–°æ™ºèƒ½ç¼“å­˜ä¸­çš„ç¼ºå¤±è§†é¢‘åˆ—è¡¨ï¼ˆç”¨äºåç»­åªæ›´æ–°ï¼‰
                        if self.smart_cache and self.smart_cache.enabled:
                            self.smart_cache.update_missing_videos(model_name, missing_with_urls)
                
                self.logger.info(f"[çº¿ç¨‹-{thread_id}] {model_name}: ğŸ“ æŠ¥å‘Šå·²ä¿å­˜")
            
            return result
            
        except Exception as e:
            self.logger.error(f"[çº¿ç¨‹-{thread_id}] {model_name}: å¤„ç†å¼‚å¸¸: {e}")
            self._update_stats(False)
            return ModelResult(
                model_name=model_name,
                success=False,
                error_message=str(e),
                country=country,
                local_folder=original_dir,
                local_folder_full=folder
            )


def process_models_multithreaded(
    local_matches: List[Tuple],
    config: dict,
    module_type: int,
    logger: logging.Logger,
    missing_logger: logging.Logger,
    countries_dir: str,
    smart_cache: SmartCache,
    running_flag=None
) -> List[ModelResult]:
    """
    ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘å¤„ç†æ¨¡ç‰¹
    
    Args:
        local_matches: æœ¬åœ°æ¨¡ç‰¹åŒ¹é…åˆ—è¡¨
        config: é…ç½®å­—å…¸
        module_type: æ¨¡å—ç±»å‹
        logger: ä¸»æ—¥å¿—è®°å½•å™¨
        missing_logger: ç¼ºå¤±è§†é¢‘æ—¥å¿—è®°å½•å™¨
        countries_dir: å›½å®¶åˆ†ç±»ç›®å½•
        smart_cache: æ™ºèƒ½ç¼“å­˜å®ä¾‹
        running_flag: è¿è¡Œæ ‡å¿—
        
    Returns:
        ModelResult åˆ—è¡¨
    """
    # è·å–çº¿ç¨‹æ•°é…ç½®
    max_workers = config.get('multithreading', {}).get('max_workers', 3)
    max_workers = min(max_workers, len(local_matches))  # ä¸è¶…è¿‡æ¨¡ç‰¹æ•°é‡
    
    logger.info(f"\nğŸš€ å¯åŠ¨å¤šçº¿ç¨‹å¤„ç†ï¼Œå·¥ä½œçº¿ç¨‹æ•°: {max_workers}")
    logger.info(f"ğŸ“Š æ€»æ¨¡ç‰¹æ•°: {len(local_matches)}")
    logger.info("=" * 60)
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = ModelProcessor(
        config, module_type, logger, missing_logger,
        countries_dir, smart_cache, running_flag
    )
    
    results = []
    completed = 0
    failed = 0
    
    # ä½¿ç”¨ ThreadPoolExecutor å¹¶å‘å¤„ç†
    with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="ModelWorker") as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_model = {
            executor.submit(processor.process_single_model, model_info): model_info
            for model_info in local_matches
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_model):
            model_info = future_to_model[future]
            model_name = model_info[0]
            
            try:
                result = future.result()
                results.append(result)
                
                if result.success:
                    completed += 1
                    if result.missing_count > 0:
                        logger.info(f"âœ… [{completed}/{len(local_matches)}] {model_name}: å‘ç° {result.missing_count} ä¸ªç¼ºå¤±")
                    else:
                        logger.info(f"âœ… [{completed}/{len(local_matches)}] {model_name}: æ— ç¼ºå¤±")
                else:
                    failed += 1
                    logger.error(f"âŒ [{completed + failed}/{len(local_matches)}] {model_name}: {result.error_message}")
                    
            except Exception as e:
                failed += 1
                logger.error(f"âŒ [{completed + failed}/{len(local_matches)}] {model_name}: ä»»åŠ¡å¼‚å¸¸ - {e}")
                results.append(ModelResult(
                    model_name=model_name,
                    success=False,
                    error_message=str(e)
                ))
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if running_flag is not None:
                should_stop = not running_flag() if callable(running_flag) else not running_flag
                if should_stop:
                    logger.info("âš  ç”¨æˆ·è¯·æ±‚åœæ­¢ï¼Œå–æ¶ˆå‰©ä½™ä»»åŠ¡...")
                    # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                    for f in future_to_model:
                        if not f.done():
                            f.cancel()
                    break
    
    logger.info(f"\nğŸ“Š å¤šçº¿ç¨‹å¤„ç†å®Œæˆ: æˆåŠŸ {completed} | å¤±è´¥ {failed} | æ€»è®¡ {len(local_matches)}")
    
    return results


def generate_reports(all_missing: List[ModelResult], config: dict, 
                     module_type: int, processed_count: int, 
                     error_count: int, logger: logging.Logger):
    """ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶"""
    
    logger.info("\n" + "=" * 60)
    logger.info("å¤„ç†å®Œæˆï¼")
    logger.info(f"âœ… æˆåŠŸå¤„ç†: {processed_count} ä¸ªæ¨¡ç‰¹")
    logger.info(f"âŒ å¤„ç†å¤±è´¥: {error_count} ä¸ªæ¨¡ç‰¹")
    logger.info(f"ğŸ”´ å‘ç°ç¼ºå¤±: {len(all_missing)} ä¸ªæ¨¡ç‰¹æœ‰ç¼ºå¤±è§†é¢‘")
    
    # è¿‡æ»¤å‡ºæœ‰ç¼ºå¤±çš„æ¨¡ç‰¹
    missing_models = [r for r in all_missing if r.missing_count > 0]
    
    if missing_models:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ç”ŸæˆTXTæ ¼å¼çš„ç¼ºå¤±æ¸…å•
        txt_path = os.path.join(config['output_dir'], f"missing_summary_{timestamp}.txt")
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ç¼ºå¤±è§†é¢‘æ¸…å•\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"è¿è¡Œæ¨¡å—: {'PORN' if module_type == 1 else 'JAVDB' if module_type == 2 else 'è‡ªåŠ¨æ¨¡å¼'}\n")
            f.write("=" * 60 + "\n\n")
            
            for result in missing_models:
                f.write(f"[{result.model_name}]\n")
                f.write(f"æœ¬åœ°ç›®å½•: {result.local_folder}\n")
                f.write(f"åœ¨çº¿é“¾æ¥: {result.url}\n")
                f.write(f"ç»Ÿè®¡: æœ¬åœ° {result.local_count} ä¸ª | åœ¨çº¿ {result.online_count} ä¸ª | æ–°è§†é¢‘ {result.new_videos_count} ä¸ª | ç¼ºå¤± {result.missing_count} ä¸ª\n")
                f.write("-" * 50 + "\n")
                
                for i, (title, video_url) in enumerate(result.missing_with_urls, 1):
                    f.write(f"{i:3d}. {title}\n")
                    if video_url:
                        f.write(f"    é“¾æ¥: {video_url}\n")
                
                f.write("\n" + "=" * 60 + "\n\n")
        
        # 2. ç”ŸæˆJSONæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š
        json_path = os.path.join(config['output_dir'], f"missing_detail_{timestamp}.json")
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump({
                "generated_at": datetime.now().isoformat(),
                "total_models_processed": processed_count,
                "models_with_missing": len(missing_models),
                "running_module": "PORN" if module_type == 1 else "JAVDB" if module_type == 2 else "AUTO",
                "missing_details": [
                    {
                        "model": r.model_name,
                        "url": r.url,
                        "local_folder": r.local_folder,
                        "local_count": r.local_count,
                        "online_count": r.online_count,
                        "new_videos_count": r.new_videos_count,
                        "missing_count": r.missing_count,
                        "missing_titles": r.missing_titles,
                        "missing_with_urls": r.missing_with_urls
                    }
                    for r in missing_models
                ]
            }, f, ensure_ascii=False, indent=2)
        
        # 3. ç”Ÿæˆç®€åŒ–çš„å½“å‰ç¼ºå¤±æ–‡ä»¶
        current_txt_path = os.path.join(config['output_dir'], "missing_current.txt")
        with open(current_txt_path, 'w', encoding='utf-8') as f:
            for result in missing_models:
                f.write(f"#{result.model_name}#{result.url}\n")
                for title in result.missing_titles:
                    f.write(f"{title}\n")
                f.write("\n")
        
        logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {txt_path}")
        logger.info(f"ğŸ“„ JSONæ•°æ®å·²ä¿å­˜: {json_path}")
        logger.info(f"ğŸ“„ å½“å‰ç¼ºå¤±æ¸…å•: {current_txt_path}")
        
    else:
        logger.info("ğŸ‰ æ­å–œï¼æ‰€æœ‰æ¨¡ç‰¹çš„æœ¬åœ°è§†é¢‘éƒ½å®Œæ•´æ— ç¼ºï¼")
    
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶ä½ç½®: {config['log_dir']}")
    logger.info("=" * 60)


# --- ä¸»ç¨‹åº ---
def main(module_arg="auto", local_dirs=None, scraper="selenium", running_flag=None):
    """ä¸»ç¨‹åºå…¥å£
    
    Args:
        module_arg: æ¨¡å—ç±»å‹å‚æ•°ï¼Œå¯é€‰å€¼: "auto", "porn", "javdb"
        local_dirs: æœ¬åœ°ç›®å½•è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
        scraper: æŠ“å–å·¥å…·ï¼Œå¯é€‰å€¼: "selenium", "playwright", "drissionpage", "zendriver"
        running_flag: è¿è¡Œæ ‡å¿—ï¼Œç”¨äºæ§åˆ¶ç¨‹åºæ˜¯å¦ç»§ç»­è¿è¡Œ
    """
    # åˆå§‹åŒ–æ—¥å¿—å™¨ï¼ˆæå‰åˆå§‹åŒ–ä»¥ä¾¿é”™è¯¯å¤„ç†ï¼‰
    logger = logging.getLogger(__name__)
    
    try:
        # æ¨¡å—é€‰æ‹©
        if module_arg == "porn":
            module_type = 1
        elif module_arg == "javdb":
            module_type = 2
        else:  # auto
            module_type = 3
        
        # åŠ è½½é…ç½®
        config = load_config()
        models = load_models()
        
        # é…ç½®éªŒè¯ï¼ˆæ–°å¢ï¼‰
        logger.info("ğŸ” æ­£åœ¨éªŒè¯é…ç½®æ–‡ä»¶...")
        validation_result = validate_config_file("config.yaml")
        if not validation_result.valid:
            logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œç¨‹åºæ— æ³•ç»§ç»­è¿è¡Œ")
            print_validation_report(validation_result)
            logger.error("\nè¯·ä¿®å¤ä¸Šè¿°é…ç½®é—®é¢˜åé‡æ–°è¿è¡Œç¨‹åº")
            logger.error("ğŸ’¡ æç¤ºï¼šå¯ä»¥è¿è¡Œ 'python -m core.modules.common.config_validator' å•ç‹¬éªŒè¯é…ç½®")
            sys.exit(1)
        elif validation_result.warnings:
            logger.warning(f"âš ï¸  é…ç½®éªŒè¯å‘ç° {len(validation_result.warnings)} ä¸ªè­¦å‘Š:")
            for warning in validation_result.warnings:
                logger.warning(f"  - {warning}")
        else:
            logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        
        # ChromeDriveræ£€æŸ¥ï¼ˆæ–°å¢ï¼‰
        if config.get('use_selenium', False) or config.get('scraper', '') == 'selenium':
            logger.info("\nğŸ” æ­£åœ¨æ£€æŸ¥ChromeDriver...")
            driver_success, driver_message = check_and_setup_chromedriver(config)
            if driver_success:
                logger.info(f"âœ… {driver_message}")
            else:
                logger.warning(f"âš ï¸  ChromeDriveræ£€æŸ¥å¤±è´¥: {driver_message}")
                logger.warning("ğŸ’¡ ç¨‹åºå°†ç»§ç»­è¿è¡Œï¼Œä½†åœ¨ä½¿ç”¨Seleniumæ—¶å¯èƒ½ä¼šå‡ºç°é—®é¢˜")
        
        # å¦‚æœæä¾›äº†æœ¬åœ°ç›®å½•ï¼Œåˆ™è¦†ç›–é…ç½®
        if local_dirs:
            config['local_roots'] = local_dirs
        
        # å¦‚æœæä¾›äº†æŠ“å–å·¥å…·ï¼Œåˆ™è¦†ç›–é…ç½®
        config['scraper'] = scraper
        
        # è®¾ç½®æ—¥å¿—
        logger, missing_logger, countries_dir = setup_logging(config['log_dir'])
        
        # è·å–å¤šçº¿ç¨‹é…ç½®
        multithreading_config = config.get('multithreading', {})
        use_multithreading = multithreading_config.get('enabled', True)
        max_workers = multithreading_config.get('max_workers', 3)
        
        logger.info("ğŸš€ å¯åŠ¨æ‰¹é‡æ¨¡ç‰¹è§†é¢‘åŒæ­¥æ£€æŸ¥ç³»ç»Ÿï¼ˆå¤šçº¿ç¨‹ä¼˜åŒ–ç‰ˆæœ¬ï¼‰")
        logger.info("=" * 60)
        logger.info(f"é…ç½®æ–‡ä»¶: config.yaml")
        logger.info(f"æ¨¡ç‰¹æ•°é‡: {len(models)}")
        logger.info(f"æœ¬åœ°ç›®å½•: {config['local_roots']}")
        logger.info(f"è¾“å‡ºç›®å½•: {config['output_dir']}")
        logger.info(f"æŠ“å–å·¥å…·: {config.get('scraper', 'selenium')}")
        logger.info(f"æœ€å¤§ç¿»é¡µ: {config.get('max_pages', 'æ— é™åˆ¶')}")
        logger.info(f"è¿è¡Œæ¨¡å—: {'PORN' if module_type == 1 else 'JAVDB' if module_type == 2 else 'è‡ªåŠ¨æ¨¡å¼'}")
        logger.info(f"å¤šçº¿ç¨‹æ¨¡å¼: {'å¯ç”¨' if use_multithreading else 'ç¦ç”¨'} ({max_workers} å·¥ä½œçº¿ç¨‹)")
        logger.info("=" * 60)
        
        # ä»£ç†è¿æ¥é¢„æ£€ï¼ˆå¢å¼ºç‰ˆï¼‰
        proxy_config = config.get('network', {}).get('proxy', {})
        if not proxy_config:
            proxy_config = config.get('proxy', {})
        
        if proxy_config.get('enabled', False):
            logger.info("\nğŸ” æ£€æµ‹åˆ°å·²å¯ç”¨ä»£ç†ï¼Œæ­£åœ¨è¿›è¡Œå…¨é¢è¿æ¥æµ‹è¯•...")
            
            proxy_type = proxy_config.get('type', 'http')
            proxy_host = proxy_config.get('host', '127.0.0.1')
            proxy_port = proxy_config.get('port', '10808')
            logger.info(f"   ä»£ç†ç±»å‹: {proxy_type}")
            logger.info(f"   ä»£ç†åœ°å€: {proxy_host}:{proxy_port}")
            
            # ä½¿ç”¨å¢å¼ºç‰ˆä»£ç†æ£€æŸ¥
            tester = EnhancedProxyTester(proxy_config, timeout=15)
            check_result = tester.comprehensive_check()
            
            # æ‰“å°è¯¦ç»†æŠ¥å‘Š
            print_comprehensive_report(check_result)
            
            if not check_result.overall_success:
                logger.error("\n" + "=" * 60)
                logger.error("âŒ ä»£ç†è¿æ¥æ£€æŸ¥å¤±è´¥ï¼")
                logger.error("=" * 60)
                logger.error("\næ£€æµ‹åˆ°çš„é—®é¢˜ï¼š")
                # æ­£ç¡®è®¿é—®ComprehensiveProxyCheckçš„å±æ€§
                test_results = [
                    ("åŸºç¡€TCPè¿æ¥", check_result.basic_connectivity.success, check_result.basic_connectivity.error_message),
                    ("HTTPè®¿é—®", check_result.http_access.success, check_result.http_access.error_message),
                    ("HTTPSè®¿é—®", check_result.https_access.success, check_result.https_access.error_message)
                ]
                
                # æ·»åŠ ç›®æ ‡ç½‘ç«™æµ‹è¯•ç»“æœ
                for target_result in check_result.target_websites:
                    test_results.append((
                        f"ç›®æ ‡ç½‘ç«™({target_result.host})", 
                        target_result.success, 
                        target_result.error_message
                    ))
                
                for test_name, status, message in test_results:
                    if not status:
                        logger.error(f"  â€¢ {test_name}: {message}")
                
                logger.error("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š")
                logger.error("  1. æ£€æŸ¥ä»£ç†æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
                logger.error("  2. éªŒè¯ä»£ç†åœ°å€å’Œç«¯å£é…ç½®")
                logger.error("  3. ç¡®è®¤ä»£ç†è®¤è¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰")
                logger.error("  4. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®")
                logger.error("  5. å°è¯•ç¦ç”¨ä»£ç†ä½¿ç”¨ç›´è¿")
                logger.error("=" * 60)
                
                # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­ï¼ˆä»…åœ¨æœ‰æ§åˆ¶å°çš„æƒ…å†µä¸‹ï¼‰
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„stdin
                    if sys.stdin and sys.stdin.isatty():
                        user_input = input("\næ˜¯å¦ç»§ç»­è¿è¡Œç¨‹åºï¼Ÿ(y/N): ").strip().lower()
                        if user_input not in ['y', 'yes']:
                            logger.info("ç”¨æˆ·é€‰æ‹©é€€å‡ºç¨‹åº")
                            sys.exit(1)
                    else:
                        # æ— æ§åˆ¶å°ç¯å¢ƒï¼Œé»˜è®¤ç»§ç»­è¿è¡Œ
                        logger.info("\nâš ï¸  æ— æ§åˆ¶å°ç¯å¢ƒï¼Œç¨‹åºå°†è‡ªåŠ¨ç»§ç»­è¿è¡Œ")
                        logger.info("æç¤ºï¼šå¦‚éœ€äº¤äº’ï¼Œè¯·åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œç¨‹åº")
                except (RuntimeError, EOFError):
                    # æ‰“åŒ…ç¯å¢ƒä¸‹çš„å¼‚å¸¸å¤„ç†
                    logger.info("\nâš ï¸  æ— æ³•è·å–ç”¨æˆ·è¾“å…¥ï¼Œç¨‹åºå°†è‡ªåŠ¨ç»§ç»­è¿è¡Œ")
                    logger.info("æç¤ºï¼šä»£ç†æ£€æŸ¥å¤±è´¥ï¼Œç¨‹åºä»ä¼šç»§ç»­æ‰§è¡Œï¼Œä½†å¯èƒ½å‡ºç°ç½‘ç»œé—®é¢˜")
            else:
                logger.info("âœ… ä»£ç†è¿æ¥æ£€æŸ¥é€šè¿‡ï¼Œç»§ç»­æ‰§è¡Œ...\n")
        else:
            logger.info("\nğŸ“¡ æœªå¯ç”¨ä»£ç†ï¼Œä½¿ç”¨ç›´æ¥è¿æ¥\n")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(config['output_dir']).mkdir(exist_ok=True)
        
        # è·å–ç¼“å­˜ç›®å½•å¹¶åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜
        cache_dir = get_cache_dir(config)
        logger.info(f"ç¼“å­˜ç›®å½•: {cache_dir}")
        
        smart_cache = get_smart_cache(cache_dir, config)
        logger.info(f"æ™ºèƒ½ç¼“å­˜: {'å¯ç”¨' if smart_cache.enabled else 'ç¦ç”¨'}")
        if smart_cache.enabled:
            logger.info(f"  - å¢é‡æ›´æ–°: {'å¯ç”¨' if smart_cache.incremental_update else 'ç¦ç”¨'}")
            logger.info(f"  - é¡µé¢è¿‡æœŸæ—¶é—´: {smart_cache.page_expiry_hours} å°æ—¶")
        
        # æ‰«ææœ¬åœ°æ¨¡ç‰¹ç›®å½•
        local_matches = []
        if module_type == 1:
            local_matches = scan_porn_models(
                models,
                config['local_roots'],
                set(config['video_extensions']),
                config['filename_clean_patterns'],
                logger
            )
        elif module_type == 2:
            local_matches = scan_javdb_models(
                models,
                config['local_roots'],
                set(config['video_extensions']),
                config['filename_clean_patterns'],
                logger
            )
        else:
            porn_matches = scan_porn_models(
                models,
                config['local_roots'],
                set(config['video_extensions']),
                config['filename_clean_patterns'],
                logger
            )
            javdb_matches = scan_javdb_models(
                models,
                config['local_roots'],
                set(config['video_extensions']),
                config['filename_clean_patterns'],
                logger
            )
            seen_models = set()
            for match in porn_matches + javdb_matches:
                if match[0] not in seen_models:
                    seen_models.add(match[0])
                    local_matches.append(match)
            logger.info(f"è‡ªåŠ¨æ¨¡å¼ - åˆå¹¶åå…±æ‰¾åˆ° {len(local_matches)} ä¸ªåŒ¹é…çš„æœ¬åœ°æ¨¡ç‰¹ç›®å½•")
        
        if not local_matches:
            if module_type == 1:
                logger.error("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æœ¬åœ°æ¨¡ç‰¹ç›®å½•ï¼Œç¨‹åºé€€å‡º")
                logger.info("æç¤º: ç¡®ä¿æœ¬åœ°ç›®å½•åŒ…å«ä»¥ '[Channel] æ¨¡ç‰¹å' æ ¼å¼å‘½åçš„æ–‡ä»¶å¤¹")
            elif module_type == 2:
                logger.error("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æœ¬åœ°æ¨¡ç‰¹ç›®å½•ï¼Œç¨‹åºé€€å‡º")
                logger.info("æç¤º: ç¡®ä¿æœ¬åœ°ç›®å½•åŒ…å«ä»¥ 'æ¨¡ç‰¹å' æ ¼å¼å‘½åçš„æ–‡ä»¶å¤¹")
            else:
                logger.error("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æœ¬åœ°æ¨¡ç‰¹ç›®å½•ï¼Œç¨‹åºé€€å‡º")
                logger.info("æç¤º: ç¡®ä¿æœ¬åœ°ç›®å½•åŒ…å«ä»¥ '[Channel] æ¨¡ç‰¹å' æˆ– 'æ¨¡ç‰¹å' æ ¼å¼å‘½åçš„æ–‡ä»¶å¤¹")
            return
        
        # ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†æ¨¡ç‰¹
        if use_multithreading and len(local_matches) > 1:
            results = process_models_multithreaded(
                local_matches, config, module_type,
                logger, missing_logger, countries_dir,
                smart_cache, running_flag
            )
        else:
            # å•çº¿ç¨‹æ¨¡å¼ï¼ˆç”¨äºè°ƒè¯•æˆ–åªæœ‰ä¸€ä¸ªæ¨¡ç‰¹çš„æƒ…å†µï¼‰
            logger.info("\nä½¿ç”¨å•çº¿ç¨‹æ¨¡å¼å¤„ç†...")
            processor = ModelProcessor(
                config, module_type, logger, missing_logger,
                countries_dir, smart_cache, running_flag
            )
            results = []
            for i, model_info in enumerate(local_matches, 1):
                logger.info(f"\n[{i}/{len(local_matches)}] å¤„ç†æ¨¡ç‰¹: {model_info[0]}")
                result = processor.process_single_model(model_info)
                results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        processed_count = sum(1 for r in results if r.success)
        error_count = sum(1 for r in results if not r.success)
        
        # ç”ŸæˆæŠ¥å‘Š
        generate_reports(results, config, module_type, processed_count, error_count, logger)
        
        # è¿”å›ç»“æœä¾›GUIä½¿ç”¨
        return results
        
    except KeyboardInterrupt:
        logger.info("\nâš  ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        return []
    except Exception as e:
        logger.critical(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        logger.critical(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
        sys.exit(1)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¨¡ç‰¹æŸ¥é‡ç®¡ç†ç³»ç»Ÿ')
    parser.add_argument('--version', '-v', action='version', version='æ¨¡ç‰¹æŸ¥é‡ç®¡ç†ç³»ç»Ÿ v1.0')
    
    # è§£æå‚æ•°ä½†ä¸å¼ºåˆ¶ä½¿ç”¨
    try:
        args = parser.parse_args()
    except SystemExit:
        # å¦‚æœç”¨æˆ·è¯·æ±‚å¸®åŠ©ï¼Œæ­£å¸¸é€€å‡º
        sys.exit(0)
    
    main()
    
    # ==================== ä¿®å¤çš„å¯¹æ¯”é€»è¾‘ ====================
    def _fixed_process_single_model(self, model_info: tuple, thread_id: int = 0) -> ModelResult:
        """
        ä¿®å¤ç‰ˆå•ä¸ªæ¨¡ç‰¹å¤„ç†å‡½æ•° - ç¡®ä¿ä¸‹è½½åå¯¹æ¯”é€»è¾‘æ­£ç¡®
        """
        model_name, folder, url, country, original_dir = model_info
        
        try:
            self.logger.info(f"[çº¿ç¨‹-{thread_id}] å¼€å§‹å¤„ç†æ¨¡ç‰¹: {model_name}")
            
            # æå–æœ¬åœ°è§†é¢‘
            local_videos = extract_local_videos(folder, self.config['video_extensions'])
            local_set = {v[0] for v in local_videos}  # åªå–æ ‡é¢˜
            
            # è·å–åœ¨çº¿è§†é¢‘
            online_set, title_to_url = self._fetch_online_videos(model_name, url, thread_id)
            
            if not online_set:
                error_msg = "æ— æ³•è·å–åœ¨çº¿è§†é¢‘åˆ—è¡¨"
                self.logger.error(f"[çº¿ç¨‹-{thread_id}] {model_name}: {error_msg}")
                return ModelResult(
                    model_name=model_name,
                    success=False,
                    error_message=error_msg,
                    url=url,
                    local_folder=original_dir,
                    local_folder_full=folder,
                    country=country
                )
            
            # è·å–å·²ç¼“å­˜çš„æ ‡é¢˜
            cached_titles = self.smart_cache.get_cached_titles(model_name)
            new_videos = online_set - cached_titles
            
            # ä¿®å¤å…³é”®ï¼šæ­£ç¡®è·å–å·²ä¸‹è½½çš„è§†é¢‘
            downloaded_videos = self._get_downloaded_videos_correctly(model_name)
            
            # ä¿®å¤å…³é”®ï¼šæ­£ç¡®åˆå¹¶æœ¬åœ°å’Œå·²ä¸‹è½½è§†é¢‘
            local_set_with_downloaded = local_set | downloaded_videos
            
            # ä¿®å¤å…³é”®ï¼šæ­£ç¡®çš„å¯¹æ¯”é€»è¾‘
            missing = online_set - local_set_with_downloaded
            
            # è®°å½•è¯¦ç»†ä¿¡æ¯
            original_local_count = len(local_set)
            effective_local_count = len(local_set_with_downloaded)
            downloaded_count = len(downloaded_videos)
            
            self.logger.info(f"[çº¿ç¨‹-{thread_id}] {model_name}: "
                           f"åœ¨çº¿ {len(online_set)} | "
                           f"æ–°è§†é¢‘ {len(new_videos)} | "
                           f"æœ¬åœ° {original_local_count} | "
                           f"å·²ä¸‹è½½ {downloaded_count} | "
                           f"æœ‰æ•ˆæœ¬åœ° {effective_local_count} | "
                           f"ç¼ºå¤± {len(missing)}")
            
            # æ„å»ºç»“æœ
            result = ModelResult(
                model_name=model_name,
                success=True,
                local_count=effective_local_count,
                online_count=len(online_set),
                new_videos_count=len(new_videos),
                missing_count=len(missing),
                missing_titles=sorted(list(missing)),
                missing_with_urls=[(title, title_to_url.get(title, "")) for title in missing],
                url=url,
                local_folder=original_dir,
                local_folder_full=folder,
                country=country
            )
            
            # æ›´æ–°ç¼“å­˜
            if self.smart_cache and self.smart_cache.enabled:
                self.smart_cache.add_videos(model_name, [(title, title_to_url.get(title, ""), 1) for title in online_set])
                # æ›´æ–°ç¼ºå¤±è§†é¢‘åˆ—è¡¨
                missing_data = {title: {"status": "missing", "url": title_to_url.get(title, "")} for title in missing}
                self.smart_cache.update_missing_videos(model_name, missing_data)
            
            return result
            
        except Exception as e:
            error_msg = f"å¤„ç†æ¨¡ç‰¹å¤±è´¥: {str(e)}"
            self.logger.error(f"[çº¿ç¨‹-{thread_id}] {model_name}: {error_msg}")
            return ModelResult(
                model_name=model_name,
                success=False,
                error_message=error_msg,
                url=url,
                local_folder=original_dir,
                local_folder_full=folder,
                country=country
            )
    
    def _get_downloaded_videos_correctly(self, model_name: str) -> set:
        """
        æ­£ç¡®è·å–å·²ä¸‹è½½çš„è§†é¢‘é›†åˆ
        """
        downloaded_videos = set()
        
        if self.smart_cache and self.smart_cache.enabled:
            try:
                # ä»ç¼“å­˜ä¸­è·å–ç¼ºå¤±è§†é¢‘æ•°æ®
                cache_data = self.smart_cache.load(model_name)
                missing_data = cache_data.get('missing_videos', {})
                
                # ç­›é€‰å‡ºå·²ä¸‹è½½çš„è§†é¢‘
                for title, info in missing_data.items():
                    if info.get('status') == 'downloaded':
                        downloaded_videos.add(title)
                        
                self.logger.debug(f"ä»ç¼“å­˜è·å–åˆ° {len(downloaded_videos)} ä¸ªå·²ä¸‹è½½è§†é¢‘")
                
            except Exception as e:
                self.logger.warning(f"è·å–å·²ä¸‹è½½è§†é¢‘æ—¶å‡ºé”™: {e}")
        
        return downloaded_videos
    
    def _fetch_online_videos(self, model_name: str, url: str, thread_id: int) -> tuple:
        """
        è·å–åœ¨çº¿è§†é¢‘åˆ—è¡¨
        """
        try:
            if self.module_type == 1:  # PORN
                online_set, title_to_url = fetch_with_requests_porn(
                    url, self.config, self.smart_cache, model_name, thread_id
                )
            elif self.module_type == 2:  # JAVDB
                online_set, title_to_url = fetch_with_requests_javdb(
                    url, self.config, self.smart_cache, model_name, thread_id
                )
            else:  # AUTO
                # è‡ªåŠ¨æ£€æµ‹æ¨¡å—ç±»å‹
                if 'javdb' in url.lower():
                    online_set, title_to_url = fetch_with_requests_javdb(
                        url, self.config, self.smart_cache, model_name, thread_id
                    )
                else:
                    online_set, title_to_url = fetch_with_requests_porn(
                        url, self.config, self.smart_cache, model_name, thread_id
                    )
            
            return online_set, title_to_url
            
        except Exception as e:
            self.logger.error(f"[çº¿ç¨‹-{thread_id}] è·å–åœ¨çº¿è§†é¢‘å¤±è´¥: {e}")
            return set(), {}

